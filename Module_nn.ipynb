{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Module nn.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jn7iLkQKe01g",
        "colab_type": "text"
      },
      "source": [
        "El paquete **torch.nn** de PyTorch contiene multitud de clases que nos permiten crear de una manera intuitiva redes neuronales y a la vez tener un nivel de detalle y control de los componentes de las mismas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ir6GF4fWjNvI",
        "colab_type": "text"
      },
      "source": [
        "Una de las clases más importantes de torch.nn es **torch.nn.Module** ya que es muy útil que los modelos que definamos hereden esta clase. Para ello es necesario definir el constructor del modelo en **_init_()** instanciando los componentes que deseemos y sobreescribir el **método forward,** que realiza las operaciones forward del modelo y calcula la salida.\n",
        "Con super.__init__() inicializamos la superclase nn.Module. El método forward se ejecuta directamente al llamar al modelo gracias al método __call__.\n",
        "\n",
        "En el siguiente ejemplo creamos un modelo basándonos en la clase nn.Module, instanciamos los componentes del modelo usando las clases del paquete torch.nn nn.Linear para la capa lineal y nn.Relu para la función de activacíon ReLU y definimos el flujo de las operaciones en el método forward."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LlmL6_a-j4s_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_classes):\n",
        "        super(Net, self).__init__()                    \n",
        "        self.fc1 = nn.Linear(input_size, hidden_size)  \n",
        "        self.relu = nn.ReLU()                          \n",
        "        self.fc2 = nn.Linear(hidden_size, num_classes) \n",
        "    \n",
        "    def forward(self, x):                              \n",
        "        out = self.fc1(x)\n",
        "        out = self.relu(out)\n",
        "        out = self.fc2(out)\n",
        "        return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "afkgllYsdvAi",
        "colab_type": "code",
        "outputId": "eab32a0c-dd26-47e3-c5d8-f3eaafd005f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "#Creamos una instancia del modelo\n",
        "modelo1=Net(100,200,10)\n",
        "#Calculamos la salida con una entrada ejemplo\n",
        "x=torch.rand(100)\n",
        "output=modelo1(x)\n",
        "print(output)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([-0.1491, -0.1181,  0.0409,  0.1655, -0.0919,  0.0808, -0.1437,  0.0978,\n",
            "         0.3534, -0.0696], grad_fn=<AddBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8PjIcSVY0lzX",
        "colab_type": "text"
      },
      "source": [
        "Debido a que el modelo extiende la clase base nn.Module, es posible usar la gran cantidad de métodos y atributos de esta clase."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3-pFLhHxzM8I",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "outputId": "a65482b9-8840-431c-a13e-5c02b41172ba"
      },
      "source": [
        "#Vemos la estructura del modelo\n",
        "print(modelo1)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Net(\n",
            "  (fc1): Linear(in_features=100, out_features=200, bias=True)\n",
            "  (relu): ReLU()\n",
            "  (fc2): Linear(in_features=200, out_features=10, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bOw9bfUD1v78",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "outputId": "9e2ffee7-18da-44c1-ec91-8bb4a52f24d2"
      },
      "source": [
        "#Movemos todos los parámetros del modelo a la GPU\n",
        "modelo1.cuda()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Net(\n",
              "  (fc1): Linear(in_features=100, out_features=200, bias=True)\n",
              "  (relu): ReLU()\n",
              "  (fc2): Linear(in_features=200, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gDsDMeRw2Zq_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        },
        "outputId": "c1179a50-66a5-4a5e-9a58-39332132c801"
      },
      "source": [
        "#El método named_parameters() devuelve un iterador a los parámetros del modelo, mostrando el nombre del parámetro y el parámetro.\n",
        "for name, param in modelo1.named_parameters():\n",
        "  if param.requires_grad:\n",
        "    if name in ['fc2.weight']:\n",
        "        print (name, param.data)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fc2.weight tensor([[-0.0143,  0.0591, -0.0423,  ..., -0.0119, -0.0161, -0.0214],\n",
            "        [-0.0036, -0.0298, -0.0684,  ..., -0.0279,  0.0139, -0.0181],\n",
            "        [ 0.0083,  0.0487,  0.0115,  ...,  0.0361, -0.0298, -0.0320],\n",
            "        ...,\n",
            "        [ 0.0614,  0.0489, -0.0314,  ...,  0.0177, -0.0035,  0.0170],\n",
            "        [-0.0631,  0.0340,  0.0433,  ..., -0.0262, -0.0472, -0.0106],\n",
            "        [-0.0349, -0.0609,  0.0234,  ...,  0.0660,  0.0404,  0.0082]],\n",
            "       device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BbGqrc6a3xCB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        },
        "outputId": "c7c57889-a9ff-4e0f-acdf-2a4d4bc66791"
      },
      "source": [
        "#El método apply(fn) aplica la función fn recursivamente en cada submódulo del modelo.\n",
        "#Vamos a crear una función que inicializa los parámetros de las capas lineales y aplicarlo al modelo.\n",
        "\n",
        "def init_w(m):\n",
        "  if type(m) == nn.Linear:\n",
        "    m.weight.data.fill_(1.0)\n",
        "\n",
        "modelo1.apply(init_w)\n",
        "\n",
        "#Vemos los parámetros de la segunda capa lineal después de aplicarles la función de inicialización.\n",
        "for name, param in modelo1.named_parameters():\n",
        "  if param.requires_grad:\n",
        "    if name in ['fc2.weight']:\n",
        "        print (name, param.data)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fc2.weight tensor([[1., 1., 1.,  ..., 1., 1., 1.],\n",
            "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
            "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
            "        ...,\n",
            "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
            "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
            "        [1., 1., 1.,  ..., 1., 1., 1.]], device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_5rfuLJF5Q5W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 403
        },
        "outputId": "e1c909f0-024e-4723-e9df-495de0c7f2f5"
      },
      "source": [
        "#El módulo torch.nn también nos ofrece gran variedad de clases que definen las principales arquitecturas de deep learning.\n",
        "#Un ejemplo es torch.nn.LSTM() que se inicializa con los parámetros (input_size, hidden_size, num_layers).\n",
        "# Tiene como entrada (input,h_0,c_0) donde la forma de la entrada es (seq_len, batch, input_size).\n",
        "# La forma de los estados iniciales h_0 y c_0 es (num_layers * num_directions, batch, hidden_size) \n",
        "\n",
        "LSTM1 = nn.LSTM(10, 6, 2)\n",
        "input = torch.randn(5, 2, 10)\n",
        "h0 = torch.randn(2, 2, 6)\n",
        "c0 = torch.randn(2, 2, 6)\n",
        "output, (hn, cn) = LSTM1(input, (h0, c0))\n",
        "\n",
        "#La salida output tiene la forma (seq_len, batch, num_directions * hidden_size) y contiene la salida h_t para todos los intantes de tiempo.\n",
        "print(output)\n",
        "\n",
        "#La salida hn tiene la forma (num_layers * num_directions, batch, hidden_size) y contiene h_t para el último intantes de tiempo en cada capa.\n",
        "print(hn)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[[-0.2011,  0.1655, -0.2477,  0.1799,  0.1487,  0.0927],\n",
            "         [ 0.0904,  0.1733,  0.1654, -0.4293,  0.1613,  0.2302]],\n",
            "\n",
            "        [[-0.1106, -0.0119, -0.2052,  0.1075,  0.0456, -0.0091],\n",
            "         [ 0.0440,  0.1401, -0.0561, -0.3597, -0.0532,  0.0714]],\n",
            "\n",
            "        [[-0.0146, -0.0703, -0.1875, -0.0116, -0.0348, -0.0276],\n",
            "         [ 0.0055,  0.0685, -0.1641, -0.2310, -0.0926,  0.0364]],\n",
            "\n",
            "        [[ 0.0490, -0.0809, -0.2023, -0.0706, -0.0991, -0.0177],\n",
            "         [ 0.0049, -0.0237, -0.1936, -0.1757, -0.1100, -0.0086]],\n",
            "\n",
            "        [[ 0.0987, -0.0947, -0.2116, -0.1135, -0.1484, -0.0041],\n",
            "         [ 0.0066, -0.0227, -0.1991, -0.1505, -0.1113, -0.0345]]],\n",
            "       grad_fn=<StackBackward>)\n",
            "tensor([[[ 0.0825, -0.0972, -0.0253, -0.3673, -0.1815, -0.2375],\n",
            "         [-0.3572, -0.1458, -0.0946, -0.3145, -0.0119,  0.2615]],\n",
            "\n",
            "        [[ 0.0987, -0.0947, -0.2116, -0.1135, -0.1484, -0.0041],\n",
            "         [ 0.0066, -0.0227, -0.1991, -0.1505, -0.1113, -0.0345]]],\n",
            "       grad_fn=<StackBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}