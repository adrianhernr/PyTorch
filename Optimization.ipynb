{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AutogradExemple.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pVH9AOw05gO6",
        "colab_type": "text"
      },
      "source": [
        "En posts pasados hemos visto los tensores en PyTorch y el módulo de redes neuronales nn.module. En este vamos a ver todo el proceso de entrenamiento de una red neuronal: creación del modelo, procesamiento la entrada a través del modelo, computar la pérdida y actualizar los parémtros del modelo usando descenso por gradiente en función de la pérdida. \n",
        "\n",
        "Primero importamos las principales librerías, incluída torch.autograd para optimización, y definimos los parámetros del módelo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VJ3Iz0Uw7M_O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset\n",
        "import torchvision.datasets as dsets\n",
        "import torchvision.transforms as transforms\n",
        "from torch.autograd import Variable\n",
        "\n",
        "\n",
        "input_size    = 10\n",
        "output_size    = 1   \n",
        "hidden_size   = 50   \n",
        "train_size= 5000\n",
        "batch_size=10    \n",
        "num_epochs    = 10     \n",
        "learning_rate = 1e-3 \n",
        "random=0 "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g03zNjh47wAc",
        "colab_type": "text"
      },
      "source": [
        "Creamos la secuencia de entrenamiento. Calculamos el número de secuencias de tamaño batch_size que contendrá la secuencia de entrenamiento. Creamos la secuencia de entrenamiento usando torch.normal y la salida, que en función del parámetro random, será una combinación lineal de la entrada o una salida aleatoria."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UYfwuA4A7uWt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "len=int(train_size/batch_size)\n",
        "\n",
        "input=torch.normal(0, 1, size=(train_size, input_size))\n",
        "input=input/input.max()\n",
        "\n",
        "linear1=nn.Linear(input_size, output_size)\n",
        "\n",
        "if random==0:\n",
        "  with torch.no_grad():\n",
        "      label=linear1(input)\n",
        "else:\n",
        "      label=torch.normal(0, 1, size=(train_size, output_size))\n",
        "      label=label/label.max()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jFHsE_3P8-fh",
        "colab_type": "text"
      },
      "source": [
        "Definimos el modelo, extendiendo la clase nn.Module. El modelo tiene una capa lineal, una ReLu y otra capa lineal, para poder hacer predicciones. Creamos una instancia del modelo con el tamaño la entrada, capas intermedias y salida indicados."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RL8dUZY584ax",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_classes):\n",
        "        super(Net, self).__init__()                    \n",
        "        self.fc1 = nn.Linear(input_size, hidden_size)  \n",
        "        self.relu1 = nn.ReLU()                          \n",
        "        self.fc2 = nn.Linear(hidden_size, output_size) \n",
        "    \n",
        "    def forward(self, x):                              \n",
        "        out = self.fc1(x)\n",
        "        out = self.relu1(out)\n",
        "        out = self.fc2(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "net = Net(input_size, hidden_size, output_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RZ6H2-P29yMW",
        "colab_type": "text"
      },
      "source": [
        "Vamos a proceder con el entrenamiento del modelo. Creamos una instancia de la función de pérdidas torch.nn.L1Loss(), que calcula la desviación absoluta media entre dos tensores. Usamos el paquete torch.optim que implementa varios algoritmos de optimización, creando una instancia del algoritmo adam, especificando los parámetros a optimizar y la learning rate. \n",
        "\n",
        "Creamos el blucle de entrenamiento, donde para cada epoch (secuencia completa de entrenamiento), para cada batch de la entrada, borra los gradientes de los parámetros, selecciona la secuencia de entrada y salida, procesa la entrada con el modelo y la compara con la salida para calcular el error con  loss = criterion(output, label1). Una vez calculado el error, se computa el gradiente de los parámetros con loss.backward() y se actualizan los parámetros usando este gradiente con optimizer.step()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MZrygCZ58x6Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "criterion = nn.L1Loss()\n",
        "optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    for i in range(len):      \n",
        "        optimizer.zero_grad()\n",
        "        input1=input[i*batch_size:(i+1)*batch_size]\n",
        "        label1=label[i*batch_size:(i+1)*batch_size]                             \n",
        "        output = net(input1)                             \n",
        "        loss = criterion(output, label1)                 \n",
        "        loss.backward()                                   \n",
        "        optimizer.step()                                  \n",
        "        \n",
        "        if (i==0) or ((i+1) % 100 == 0):                              \n",
        "            print('Epoch [%d/%d], Step [%d/%d], Loss: %.4f'\n",
        "                 %(epoch+1, num_epochs, i+1, len, loss.data))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0cpoaN6cBlub",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Por último, a título ilustrativo, creamos una secuencia de entrada-salida, procesamos la entrada con el modelo y lo comparamos con la salida esperada."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bxhzwwq5VQhj",
        "colab_type": "code",
        "outputId": "52981732-4e57-41f8-9684-7372f11d9a96",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "input11=torch.normal(0, 1, size=(10,))\n",
        "input11=input11/input11.max()\n",
        "label11=linear1(input11)\n",
        "print(label11)\n",
        "output11=net(input11)\n",
        "print(output11)\n",
        "print(criterion(output11, label11))\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([-0.1933], grad_fn=<AddBackward0>)\n",
            "tensor([-0.1913], grad_fn=<AddBackward0>)\n",
            "tensor(0.0021, grad_fn=<MeanBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}