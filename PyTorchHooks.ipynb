{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PyTorchHooks.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "En programación, nos referimos a un hook como el conjunto de técnicas que modifican o aumentan el comportamiento de un programa ante un evento. Esto suele usarse para depurar un programa o ampliar su funcionalidad.\n",
        "\n",
        "En PyTorch, un hook se puede registrar para el objeto tensor o para el objeto nn.module y los eventos que los activan son el forward o el backward pass del objeto. Es decir, el hook se ejecutará cuando nuestro modelo en PyTorch esté implementando el grafo computacional (forward pass) o cuando se estén calculando los gradientes (backward pass).\n",
        "\n",
        "Los hooks nos permitirán actuar sobre la entrada, salida o los atributos de un módulo y los atributos de un tensor.\n",
        "\n",
        "Para implementar un hook, primero tendremos que definirlos, indicando las acciones que realiza sobre el módulo o tensor.\n",
        "\n"
      ],
      "metadata": {
        "id": "ekE6AJZ4o-aH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn, Tensor\n",
        "\n",
        "def module_hook(module: nn.Module, input: Tensor, output: Tensor):\n",
        "    # Hook para nn.Module\n",
        "    # Acciones\n",
        "    \n",
        "def tensor_hook(grad: Tensor):\n",
        "    # Hook para tensor. Sólo en el backward pass\n",
        "    # Acciones"
      ],
      "metadata": {
        "id": "Y03BO3S8s_pZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Después tendremos que registrar el hook en el módulo con \"torch.nn.modules.module.register_forward_hook(hook)\" o en el tensor con \"tensor.register_hook(tensor_hook)\".\n",
        "\n",
        "A continuación vamos a ver un ejemplo de creación de un hook en un módulo. Vamos a crear un modelo de red neuronal básica con dos capas, definimos un hook para inspeccionar la entrada y la salida de la capa y lo registramos en la segunda capa del modelo."
      ],
      "metadata": {
        "id": "Jom4Xe73tOjF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_classes):\n",
        "        super(Net, self).__init__()                    \n",
        "        self.fc1 = nn.Linear(input_size, hidden_size)  \n",
        "        self.relu = nn.ReLU()                          \n",
        "        self.fc2 = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "    \n",
        "    def forward(self, x):                              \n",
        "        out = self.fc1(x)\n",
        "        out = self.relu(out)\n",
        "        out = self.fc2(out)\n",
        "        return out\n",
        "\n",
        "#Creamos una instancia del modelo\n",
        "modelo1=Net(100,200,10)\n",
        "\n",
        "#Definimo la función hook\n",
        "def module_hook(self, input, output):\n",
        "\n",
        "    print('Dentro de ' + self.__class__.__name__ + ' forward')\n",
        "    print('')\n",
        "    print('input: ', type(input))\n",
        "    print('input[0]: ', type(input[0]))\n",
        "    print('output: ', type(output))\n",
        "    print('')\n",
        "    print('input size:', input[0].size())\n",
        "    print('output size:', output.data.size())\n",
        "    print('output norm:', output.data.norm())\n",
        "\n",
        "#Registamos el hook en la segunda capa\n",
        "modelo1.fc2.register_forward_hook(module_hook)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "--wyACuDvWzm",
        "outputId": "0e13323f-a3d2-49f9-b59f-b4cc1ed42f06"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch.utils.hooks.RemovableHandle at 0x7f9fef6a76d0>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Calculamos la salida con una entrada ejemplo. Forward pass\n",
        "x=torch.rand(100)\n",
        "output=modelo1(x)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NFfUWtsnvcDL",
        "outputId": "69b12998-6cd0-4c0b-eeaf-a516e9dd1198"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dentro de Linear forward\n",
            "\n",
            "input:  <class 'tuple'>\n",
            "input[0]:  <class 'torch.Tensor'>\n",
            "output:  <class 'torch.Tensor'>\n",
            "\n",
            "input size: torch.Size([200])\n",
            "output size: torch.Size([10])\n",
            "output norm: tensor(0.2997)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vemos como cuando se ejecuta el forward pass de nuestro modelo con una entrada ejemplo, se ejecuta el hook registrado en la segunda capa y muestra para esta capa los tipos y tamaños de los tensores entrada y salida y la norma del tensor salida. "
      ],
      "metadata": {
        "id": "6ZpPBmjQzubQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AzRzFMRqo6_I"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ]
}