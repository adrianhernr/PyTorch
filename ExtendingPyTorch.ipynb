{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ExtendingPyTorch.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPhBxJMeHFoJusJfg4MZXrk"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"sxTTIJqu0NFr"},"source":["En este post de nuestro tutorial de deep learning con PyToch vamos a ver como extender PyTorch. Si quieremos implementar un nuevo módulo o función no disponible en las librerías de PyTorch tenemos varias opciones dependiendo del caso:\n","\n","*   Si queremos añadir **primitivas clásicas** (if, while,...) en un módulo. Simplemente insertaremos las primitivas en el método forward de nuetro modelo.\n","*   Si la función que queremos desarrollar se puede escribir usando operaciones de PyTorch y entonces autograd es capaz de registrar las operaciones y calcular los gradientes. En este caso **crearemos un módulo.**\n","*   Si vamos a usar operaciones no nativas de PyTorch y queremos que sean diferenciables junyo al resto del modelo. En este caso crearemos una **subclasse Function** para implementar la operación.\n","\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"UuvVkkNe4E0A"},"source":["**Añadir primitivas clásicas**\n","\n","Cuando queremos tener condicionantes o sentencias de programación como un \"if else\", \"while\"... tenemos que insertarlos en el método forward de nuestro módelo. Por ejemplo, a continuación vemos el método forward de la clase MultiheadAttention que hereda de la clase module. Podemos ver cómo implementa varios condicionales \"if else\"."]},{"cell_type":"code","metadata":{"id":"s7ijEVfc5blw"},"source":["        if self.batch_first:\n","            query, key, value = [x.transpose(1, 0) for x in (query, key, value)]\n","\n","        if not self._qkv_same_embed_dim:\n","            attn_output, attn_output_weights = F.multi_head_attention_forward(\n","                query, key, value, self.embed_dim, self.num_heads,\n","                self.in_proj_weight, self.in_proj_bias,\n","                self.bias_k, self.bias_v, self.add_zero_attn,\n","                self.dropout, self.out_proj.weight, self.out_proj.bias,\n","                training=self.training,\n","                key_padding_mask=key_padding_mask, need_weights=need_weights,\n","                attn_mask=attn_mask, use_separate_proj_weight=True,\n","                q_proj_weight=self.q_proj_weight, k_proj_weight=self.k_proj_weight,\n","                v_proj_weight=self.v_proj_weight)\n","        else:\n","            attn_output, attn_output_weights = F.multi_head_attention_forward(\n","                query, key, value, self.embed_dim, self.num_heads,\n","                self.in_proj_weight, self.in_proj_bias,\n","                self.bias_k, self.bias_v, self.add_zero_attn,\n","                self.dropout, self.out_proj.weight, self.out_proj.bias,\n","                training=self.training,\n","                key_padding_mask=key_padding_mask, need_weights=need_weights,\n","                attn_mask=attn_mask)\n","        if self.batch_first:\n","            return attn_output.transpose(1, 0), attn_output_weights\n","        else:\n","            return attn_output, attn_output_weights"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"v9QFPXYS5zS4"},"source":["**Crear un nuevo módulo**\n","\n","En este caso, definimos un nuevo módulo que herede de la clase nn.Module. En el método de inicialización init instanciamos todos los objetos que vayamos a usar y en el método forward definimos el grafo de operaciones de PyTorch que va a desarrollar el módulo. A continuación vemos la estructura del código."]},{"cell_type":"code","metadata":{"id":"qmNa8s-v61T5"},"source":["class MyLinearLayer(nn.Module):\n","    \"\"\" Custom Linear layer but mimics a standard linear layer \"\"\"\n","    def __init__(self, size_in, size_out):\n","        super().__init__()\n","        # initialize the objects\n","\n","    def forward(self, x):\n","        #Define the sequence of PyTorch operations, \n","        #including differentiable and non-differentiable operations\n","        return result"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"H8hh9ss_76iR"},"source":["**Crear una nueva función**\n","\n","Este caso, descrito [aquí](https://pytorch.org/docs/stable/notes/extending.html), es el más complicado y por ello el último recurso. Es necesario crear una subclase de Function y definir el método forward() y backward(), llamar a los métodos apropiados en el argumento ctx, declarar si la función soporta doble backward y validar que los gradientes son correctos usando gradcheck. \n","\n","En el forward, recibimos un tensor que contiene la entrada y devolvemos un tensor que contiene la salida. ctx es un objeto de contexto que se puede utilizar para almacenar información para el backward. Puede almacenar en caché objetos arbitrarios para usarlos en el backward utilizando el método ctx.save_for_backward.\n","\n","En el backward recibimos un tensor que contiene el gradiente de la pérdida con respecto a la salida, y necesitamos calcular el gradiente de la pérdida con respecto a la entrada."]},{"cell_type":"code","metadata":{"id":"T_pazrdz0J1k"},"source":[""],"execution_count":null,"outputs":[]}]}